# -*- coding: utf-8 -*-
"""CAR PRICE PREDECTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gaR-j-eLqyUaMzvDEpDynG4ttRD2-mMS

###Importing Libraries###
"""

import tensorflow as tf  ## creating models
import pandas as pd ### reading and processing data
import seaborn as sns ## visualization
from tensorflow.keras.layers import Normalization, Dense ## creating layers
from tensorflow.keras.losses import MeanSquaredError, Huber, MeanAbsoluteError ## loss function
from tensorflow.keras.optimizers import Adam ## optimizer
from matplotlib import pyplot as plt ## plotting
from tensorflow.keras.metrics import RootMeanSquaredError ## metric

"""###Data Loading and Preparation###"""

data = pd.read_csv('train.csv')

# First 10 rows of dataset
data.head(10)

#Shape of dataset
data.shape

# Finding null values
data.isnull().sum()

sns.pairplot(data[['years', 'km', 'rating', 'condition', 'economy', 'top speed', 'hp', 'torque', 'current price']], diag_kind='auto')

# Converting Data into Tensor
tensor_data = tf.constant(data)
tensor_data = tf.cast(tensor_data, tf.float32)
print(tensor_data, "\n", tensor_data.shape)

# Shuffeled data
tensor_data = tf.random.shuffle(tensor_data)
print(tensor_data[:5])

X = tensor_data[:, 3:-1]
print(X[:5])
y = tensor_data[:, -1]
print(y[:5].shape)
y = tf.expand_dims(y, axis= -1)
print(y[:5])
#

"""###Validation and Testing###"""

TRAIN_RATIO = 0.8
VAL_RATIO = 0.1
TEST_RATIO = 0.1
DATASET_SIZE = len(X)

X_train = X[:int(TRAIN_RATIO * DATASET_SIZE)]
Y_train = y[:int(TRAIN_RATIO * DATASET_SIZE)]
print(X_train.shape)
print(Y_train.shape)

X_VAL = X[int(TRAIN_RATIO * DATASET_SIZE):int(DATASET_SIZE * (TRAIN_RATIO + VAL_RATIO))]
Y_VAL = y[int(TRAIN_RATIO * DATASET_SIZE):int(DATASET_SIZE * (TRAIN_RATIO + VAL_RATIO))]
print(X_VAL.shape)
print(Y_VAL.shape)

X_test = X[int(DATASET_SIZE * (TRAIN_RATIO + VAL_RATIO)):]
Y_test = y[int(DATASET_SIZE * (TRAIN_RATIO + VAL_RATIO)):]
print(X_test.shape)
print(Y_test.shape)

"""###Normalization###

**Normalization is used in models to scale data values into a consistent range (usually 0 to 1). This helps the model learn more effectively and quickly by preventing any one feature from dominating the others due to differences in scale.**
"""

normalizer = Normalization()
normalizer.adapt(X_train)
print(normalizer(X)[:5])

"""##Building Model##

**1. Linear Regression**

**Y = mX + C**
"""

# Creating model using tensorflow
model = tf.keras.Sequential()
model.add(normalizer)
model.add(Dense(1, activation='linear'))
model.build(input_shape=(None,8))
model.summary()

tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)

"""###MSE : Mean Squared Error###
**If MSE is 0 then the model predections are perfect, the higher the MSE, the worse the model predections are.**
"""

model.compile(loss = MeanAbsoluteError(),
              optimizer=Adam(learning_rate=1.0),
              metrics = [tf.keras.metrics.RootMeanSquaredError()]) #

"""**try all three losses function to check which is better.**

###Training and Optimization###
"""

history = model.fit(X_train, Y_train, validation_data=(X_VAL, Y_VAL),  epochs=100, verbose=1)

"""*   epochs is the number of time of we are going to update our weight.


"""

plt.plot(history.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train'])
plt.show()

plt.plot(history.history['root_mean_squared_error'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train'])
plt.show()

history.history

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val_loss'])
plt.show()

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model performance')
plt.ylabel('rmse')
plt.xlabel('epoch')
plt.legend(['train', 'val'])
plt.show()

"""###Performance Measurement###"""

model.evaluate(X, y)

"""**model has a loss of 307788.5625 and rmse of 331122.3750**"""

model.evaluate(X_test, Y_test)

X_test.shape

model.predict(X_test[:5])

